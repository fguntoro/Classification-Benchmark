# Importing libraries

import yaml
import pandas as pd

# Reading configuration from a YAML file

with open("config.yaml") as file:
    global_config = yaml.load(file, yaml.FullLoader)

# Initializing variables from global config

input_dir = global_config["INPUT_DIR"] + "/"
file_label = global_config["FILE_LABEL"] + "/"
output_dir = global_config["OUTPUT_DIR"] + "/"

# Function to get groups

def get_groups(config):
    if config["GROUP"] == "all":
        df = pd.read_csv(config["FILE_LABEL"], index_col=0)
        groups = df.columns.tolist()
    else:
        groups = config["GROUP"]
    return groups


###############################
#                             #
# Rules for Feature Selection #
#                             #
###############################

# Rule for variance threshold feature selection
rule variance_threshold:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        conf = "workflow/feature_selection/rules/config.yml",
    output:
        output_dir + "{data}/{group}/feature_selection/variance_threshold_indices.csv",
    shell:
        "python workflow/feature_selection/scripts/sklearn_feature_selection.py --path_data {input.data} --config {input.conf} --group {wildcards.group} --output {output} --feature_selection VarianceThreshold"

# Rule for correlated features selection
rule correlated_features:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        indices = output_dir + "{data}/{group}/feature_selection/variance_threshold_indices.csv",
        conf = "workflow/feature_selection/rules/config.yml",
    output:
        output_dir + "{data}/{group}/feature_selection/correlated_features_indices.csv",
    shell:
        "python workflow/feature_selection/scripts/correlated_features.py --path_data {input.data} --config {input.conf} --indices {input.indices} --group {wildcards.group} --output {output} --correlation_threshold 0.90"

# Rule for consensus clustering feature selection
rule consensus_clustering:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        label = output_dir + "{data}/{group}/preprocessing/split_data/y_train.csv",
        indices = output_dir + "{data}/{group}/feature_selection/variance_threshold_indices.csv",
        conf = "workflow/feature_selection/rules/config.yml",
    output:
        output_dir + "{data}/{group}/feature_selection/consensus_clustering_indices.csv",
    shell:
        "Rscript workflow/feature_selection/scripts/consensus_clustering.R {input.data} {input.label} {input.indices} {wildcards.group} {output}"

# Function to aggregate base feature selections
def aggregate_base_feature_selection(base_feature_selections):
    files = list()
    path = output_dir + \
        "{{data}}/{{group}}/feature_selection/{base_feature_selection}_indices.csv"
    
    for base_feature_selection in base_feature_selections:
        files.append(path.format(
            base_feature_selection=base_feature_selection))
    return files

# Rule for estimator tuning
rule estimator_tuning:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        label = output_dir + "{data}/{group}/preprocessing/split_data/y_train.csv",
        indices = aggregate_base_feature_selection(
            base_feature_selections=["correlated_features", "variance_threshold"]),
        conf = "workflow/feature_selection/rules/config.yml",
    output:
        output_dir + "{data}/{group}/feature_selection/estimator_tuning/tuned_{estimator}.joblib",
    shell:
        "python workflow/feature_selection/scripts/estimator_tuning.py --path_data {input.data} --file_label {input.label} --indices {input.indices} --config {input.conf} --group {wildcards.group} --estimator_name {wildcards.estimator} --output {output}"

# Rule for stability analysis
rule stability_analysis:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        label = output_dir + "{data}/{group}/preprocessing/split_data/y_train.csv",
        indices = aggregate_base_feature_selection(
            base_feature_selections=["correlated_features", "variance_threshold"]),
        conf = "workflow/feature_selection/rules/config.yml",
    output:
        output_dir + \
            "{data}/{group}/feature_selection/stability/stability.csv",
    shell:
        "Rscript workflow/feature_selection/scripts/stability_analysis.R --path_data {input.data} --file_label {input.label} --indices {input.indices} --group {wildcards.group} --output {output}"

# Rule for Boruta feature selection
rule boruta:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        label = output_dir + "{data}/{group}/preprocessing/split_data/y_train.csv",
        indices = aggregate_base_feature_selection(
            base_feature_selections=["correlated_features", "variance_threshold"]),
        conf = "workflow/feature_selection/rules/config.yml",
        estimator = output_dir + "{data}/{group}/feature_selection/estimator_tuning/tuned_{estimator}.joblib",
    output:
        output_dir + \
            "{data}/{group}/feature_selection/boruta/boruta-{estimator}.csv",
    #wildcard_constraints:
    #    estimator = "RFC|DT|ET"
    shell:
        "python workflow/feature_selection/scripts/boruta_analysis.py --path_data {input.data} --file_label {input.label} --indices {input.indices} --config {input.conf} --group {wildcards.group} --output {output} --estimator {input.estimator}"

# Rule for generic feature selection
rule feature_selection:
    input:
        data = output_dir + "{data}/{group}/preprocessing/split_data/X_train.csv",
        label = output_dir + "{data}/{group}/preprocessing/split_data/y_train.csv",
        indices = aggregate_base_feature_selection(
            base_feature_selections=["correlated_features", "variance_threshold"]),
        conf = "workflow/feature_selection/rules/config.yml",
        estimator = output_dir + "{data}/{group}/feature_selection/estimator_tuning/tuned_{estimator}.joblib",
    output:
        output_dir + "{data}/{group}/feature_selection/{feature_selection}/{feature_selection}-{estimator}.csv",
    wildcard_constraints:
        feature_selection = "sklearn_.*"
    shell:
        "python workflow/feature_selection/scripts/sklearn_feature_selection.py --path_data {input.data} --file_label {input.label} --indices {input.indices} --config {input.conf} --group {wildcards.group} --output {output} --feature_selection {wildcards.feature_selection} --estimator {input.estimator}"